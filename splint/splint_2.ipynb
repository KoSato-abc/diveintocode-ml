{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0iN8gfHhEZp"
   },
   "source": [
    "データセットの読み込み\n",
    "\n",
    "（ kaggle の「Titanic - Machine Learning from Disaster」を使用）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "executionInfo": {
     "elapsed": 4046,
     "status": "ok",
     "timestamp": 1612313388181,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "e01cZW_cWupK",
    "outputId": "582823fb-a3b3-491f-d756-2c6fef35f15b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23870,
     "status": "ok",
     "timestamp": 1612313408017,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "URCHItkCVh2b",
    "outputId": "7f179f41-1715-42e7-fe23-463dddda4794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データセットの読み込み\n",
    "csv_path = \"../../../input/titanic/train.csv\" # ファイル名（パス）を指定する\n",
    "csv_path2 = \"../../../input/titanic/test.csv\" # ファイル名（パス）を指定する\n",
    "\n",
    "train = pd.read_csv(csv_path)\n",
    "\n",
    "test = pd.read_csv(csv_path2)\n",
    "PassengerId = test['PassengerId']\n",
    "# df = df.loc[:, [\"GrLivArea\", \"YearBuilt\", \"SalePrice\"]]\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23862,
     "status": "ok",
     "timestamp": 1612313408018,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "nAY5XYdBaHK4",
    "outputId": "0c79ddf4-3a54-4476-ef02-f7ebd6371d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23852,
     "status": "ok",
     "timestamp": 1612313408018,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "J1KEMZ9kaNdV",
    "outputId": "c7cbfc5c-8daa-4332-b6c3-156b506df462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 23852,
     "status": "ok",
     "timestamp": 1612313408019,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "AZT8hiAvW89A"
   },
   "outputs": [],
   "source": [
    "full_data = [train, test]\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "for dataset in full_data:\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n",
    "\n",
    "# Feature selection\n",
    "drop_elements = ['Cabin']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "executionInfo": {
     "elapsed": 23843,
     "status": "ok",
     "timestamp": 1612313408020,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "HelbEbSXXWki",
    "outputId": "0e054367-97d2-45c4-b37a-b3933f5dd360"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Has_Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male    1      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female    2      1   \n",
       "2                             Heikkinen, Miss. Laina  female    1      0   \n",
       "\n",
       "   Parch            Ticket  Fare  Embarked  Has_Cabin  \n",
       "0      0         A/5 21171     0         0          0  \n",
       "1      0          PC 17599     3         1          1  \n",
       "2      0  STON/O2. 3101282     1         0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6C9GoqudxdP"
   },
   "source": [
    "ベースライン（ランダムフォレスト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24066,
     "status": "ok",
     "timestamp": 1612313408253,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "ExMJARjaYG0q",
    "outputId": "9ddaba60-4f4b-408f-fe9c-2a5f3d629483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.740\n"
     ]
    }
   ],
   "source": [
    "# データを選択\n",
    "X = train.loc[:, [\"PassengerId\", \"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Has_Cabin\"]]\n",
    "y = train.loc[:, [\"Survived\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# パラメータは一先ずなし\n",
    "forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# テストデータを使ったモデルの検証\n",
    "score = forest.score(X_test, y_test)\n",
    "\n",
    "# out[score depth3 leaf5:  1.000]\n",
    "print('score :  {:0.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model    score description\n",
      "0  RandomForestClassifier  0.73991    チューニングなし\n"
     ]
    }
   ],
   "source": [
    "# 実行結果を格納する表を作成\n",
    "result_table = pd.DataFrame(columns = ['model', 'score', 'description'])\n",
    "\n",
    "result_table = result_table.append({'model': 'RandomForestClassifier', 'score': score, 'description': 'チューニングなし'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2TeGQHIfbvC"
   },
   "source": [
    "**【問題1】クロスバリデーション**\n",
    "\n",
    "事前学習期間では検証データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。\n",
    "\n",
    "\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26215,
     "status": "ok",
     "timestamp": 1612313410411,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "ekwvQPsceY1M",
    "outputId": "e9bd7f24-03bc-493e-91e3-169916946aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.611\n",
      "score :  0.697\n",
      "score :  0.640\n",
      "score :  0.663\n",
      "score :  0.719\n",
      "score :  0.629\n",
      "score :  0.652\n",
      "score :  0.663\n",
      "score :  0.596\n",
      "score :  0.685\n",
      "score平均 :  0.655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = np.arange(0)\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    # print(\"train_index:\", train_index, \"test_index:\", test_index)\n",
    "\n",
    "    # train_df = df.iloc[train_index]\n",
    "    # test_df = df.iloc[test_index]\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # インスタンス作成から学習\n",
    "    forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "    # テストデータを使ったモデルの検証\n",
    "    score = forest.score(X_test, y_test)\n",
    "\n",
    "    scores = np.append(scores, score)\n",
    "\n",
    "    # out[score depth3 leaf5:  1.000]\n",
    "    print('score :  {:0.3f}'.format(score))\n",
    "\n",
    "print('score平均 :  {:0.3f}'.format(np.average(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhBItGJSfxXC"
   },
   "source": [
    "**【問題2】グリッドサーチ**\n",
    "これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。\n",
    "\n",
    "パラメータの詳細は今後のSprintで学んでいくことになります。\n",
    "\n",
    "機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。\n",
    "\n",
    "最適なパラメータを探していくことを パラメータチューニング と呼びます。\n",
    "\n",
    "パラメータチューニングをある程度自動化する単純な方法としては グリッドサーチ があります。\n",
    "\n",
    "\n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。\n",
    "\n",
    "そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。\n",
    "\n",
    "どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126479,
     "status": "ok",
     "timestamp": 1612313510684,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "yNu1RO4iffPi",
    "outputId": "14b49712-db82-40aa-e0c2-7eb40519765d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), iid=False,\n",
       "             param_grid={'max_depth': [5, 8, 15, 25, 30, None],\n",
       "                         'min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'min_samples_split': [1, 2, 5, 10, 15, 100]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチ用のパラメータを辞書型で設定\n",
    "param = {'max_depth':[5, 8, 15, 25, 30, None],\n",
    "         'min_samples_leaf':[1, 2, 5, 10],\n",
    "         'min_samples_split':[1, 2, 5, 10, 15, 100]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(),   # グリッドサーチで決定木を定義\n",
    "                   param,\n",
    "                   cv=5,\n",
    "                   iid=False)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126470,
     "status": "ok",
     "timestamp": 1612313510685,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "x_jYZC3cf1Ue",
    "outputId": "045bff23-52a0-4cad-8071-8764df266b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最良条件:\n",
      " RandomForestClassifier(min_samples_leaf=2, min_samples_split=15)\n",
      "訓練スコア:\n",
      " 0.8042394014962594\n",
      "テストスコア:\n",
      " 0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "# スコアとパラメータの組み合わせ\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "params = clf.cv_results_['params']\n",
    "\n",
    "# 結果の確認\n",
    "best_clf = clf.best_estimator_\n",
    "print('最良条件:\\n', best_clf)\n",
    "print('訓練スコア:\\n', best_clf.score(X_train, y_train))\n",
    "print('テストスコア:\\n', best_clf.score(X_test, y_test))\n",
    "for i in range(len(scores)):\n",
    "    # print(scores[i], params[i])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = result_table.append({'model': 'RandomForestClassifier',\n",
    "                                    'score': best_clf.score(X_test, y_test),\n",
    "                                    'description': 'グリッドサーチ'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPNSIXlOgwOg"
   },
   "source": [
    "**【問題3】Kaggle Notebooksからの調査**\n",
    "\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGd-_X1_qvRt"
   },
   "source": [
    "参考ノートブック\n",
    "\n",
    "https://www.kaggle.com/imoore/titanic-the-only-notebook-you-need-to-see\n",
    "\n",
    "・現在使用していない特徴量（name等）に対して、特徴量エンジニアリングを行い、機械学習に使用する\n",
    "\n",
    "・他のモデル（XGboost)を使用する\n",
    "\n",
    "・アンサンブル学習を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gDy45omuXWf"
   },
   "source": [
    "*クロスバリデーション、グリッドサーチを実行する関数を作成しておく*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 126469,
     "status": "ok",
     "timestamp": 1612313510686,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "ep5OVPrNsPoM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# クロスバリデーションを行う関数\n",
    "def cross_val(X, y, model, n):\n",
    "\n",
    "  print(\"【クロスバリデーション】\")\n",
    "  scores = np.arange(0)\n",
    "\n",
    "  kf = KFold(n_splits=n)\n",
    "  for train_index, test_index in kf.split(X, y):\n",
    "      # print(\"train_index:\", train_index, \"test_index:\", test_index)\n",
    "\n",
    "      # train_df = df.iloc[train_index]\n",
    "      # test_df = df.iloc[test_index]\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "      # インスタンス作成から学習\n",
    "      model = model.fit(X_train, y_train)\n",
    "\n",
    "      # テストデータを使ったモデルの検証\n",
    "      score = model.score(X_test, y_test)\n",
    "\n",
    "      scores = np.append(scores, score)\n",
    "\n",
    "      # out[score depth3 leaf5:  1.000]\n",
    "      print('score :  {:0.3f}'.format(score))\n",
    "\n",
    "  print('score平均 :  {:0.3f}'.format(np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 126468,
     "status": "ok",
     "timestamp": 1612313510686,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "og9n2dluuhlN"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# グリッドサーチを実行する関数\n",
    "def gredSerch(model, param, cv_n, X_train, y_train, X_test, y_test):\n",
    "\n",
    "  print(\"【グリッドサーチ】\")\n",
    "\n",
    "  # グリッドサーチ\n",
    "  clf = GridSearchCV(model,\n",
    "                     param,\n",
    "                     cv=cv_n\n",
    "                     )\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  # スコアとパラメータの組み合わせ\n",
    "  scores = clf.cv_results_['mean_test_score']\n",
    "  params = clf.cv_results_['params']\n",
    "\n",
    "  # 結果の確認\n",
    "  best_clf = clf.best_estimator_\n",
    "  print('最良条件:\\n', best_clf)\n",
    "  print('訓練スコア:\\n', best_clf.score(X_train, y_train))\n",
    "  print('テストスコア:\\n', best_clf.score(X_test, y_test))\n",
    "  # for i in range(len(scores)):\n",
    "      # print(scores[i], params[i])\n",
    "    #  pass\n",
    "  return best_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPArEXpMryMl"
   },
   "source": [
    "***・他のモデル（XGboost)を使用する***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126696,
     "status": "ok",
     "timestamp": 1612313510924,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "Dk7bPKD3gaxk",
    "outputId": "9b7b61a9-0c53-4615-b595-54ff6283569e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.674\n"
     ]
    }
   ],
   "source": [
    "# XGboostのベースライン\n",
    "gbm = xgb.XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "# テストデータを使ったモデルの検証\n",
    "score = gbm.score(X_test, y_test)\n",
    "\n",
    "# out[score depth3 leaf5:  1.000]\n",
    "print('score :  {:0.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model     score description\n",
      "0  RandomForestClassifier  0.739910    チューニングなし\n",
      "1  RandomForestClassifier  0.786517     グリッドサーチ\n",
      "2           XGBClassifier  0.674157    チューニングなし\n"
     ]
    }
   ],
   "source": [
    "result_table = result_table.append({'model': 'XGBClassifier',\n",
    "                                    'score': score,\n",
    "                                    'description': 'チューニングなし'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126688,
     "status": "ok",
     "timestamp": 1612313510925,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "1_N61aZxtb-j",
    "outputId": "12f506ae-f765-4a5d-d36a-a96c44a843ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【クロスバリデーション】\n",
      "score :  0.721\n",
      "score :  0.652\n",
      "score :  0.697\n",
      "score :  0.708\n",
      "score :  0.624\n",
      "score平均 :  0.680\n"
     ]
    }
   ],
   "source": [
    "# XGboostでクロスバリデーション\n",
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "cross_val(X, y, gbm, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 671628,
     "status": "ok",
     "timestamp": 1612314055874,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "idYGF1XcuUbd",
    "outputId": "3f36e8b8-b7f5-4c0e-f603-63ab2cf9819f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【グリッドサーチ】\n",
      "最良条件:\n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, eta=0.025, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.0250000004, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "訓練スコア:\n",
      " 0.7468827930174564\n",
      "テストスコア:\n",
      " 0.7415730337078652\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチ\n",
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "# グリッドサーチ用のパラメータを辞書型で設定\n",
    "param = {'eta':[0.01, 0.015, 0.025, 0.3],\n",
    "         'max_depth':[3, 5, 6, 7, 9, 12],\n",
    "         'min_child_weight':[1, 3, 5, 7],\n",
    "         'subsample':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "         'colsample_bytree':[0.6, 0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "score = gredSerch(gbm, param, 4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model     score description\n",
      "0  RandomForestClassifier  0.739910    チューニングなし\n",
      "1  RandomForestClassifier  0.786517     グリッドサーチ\n",
      "2           XGBClassifier  0.674157    チューニングなし\n",
      "3           XGBClassifier  0.741573     グリッドサーチ\n"
     ]
    }
   ],
   "source": [
    "result_table = result_table.append({'model': 'XGBClassifier',\n",
    "                                    'score': score,\n",
    "                                    'description': 'グリッドサーチ'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1612315477601,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "Uj0iQ_J3v60G",
    "outputId": "5a3f6b00-f40c-4532-ee20-108db9ba7f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【クロスバリデーション】\n",
      "score :  0.637\n",
      "score :  0.607\n",
      "score :  0.736\n",
      "score :  0.747\n",
      "score :  0.775\n",
      "score平均 :  0.700\n"
     ]
    }
   ],
   "source": [
    "# XGboostでクロスバリデーション\n",
    "gbm = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.9, eta=0.01, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=0.7, verbosity=1)\n",
    "\n",
    "cross_val(X, y, gbm, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GasnPfg9gqbI"
   },
   "source": [
    "*現在使用していない特徴量（name等）に対して、特徴量エンジニアリングを行い、機械学習に使用する*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "ok",
     "timestamp": 1612316141935,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "MxOU3hoXfSLe",
    "outputId": "cbf3991f-9009-490f-cb20-109b6c40076d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Words_Count</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Parch  Fare  Embarked  Words_Count  Has_Cabin  \\\n",
       "0         0       3    1    1      0     0         0            4          0   \n",
       "1         1       1    0    2      0     3         1            7          1   \n",
       "2         1       3    0    1      0     1         0            3          0   \n",
       "3         1       1    0    2      0     3         0            7          1   \n",
       "4         0       3    1    2      0     1         0            4          0   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           2        0      1  \n",
       "1           2        0      3  \n",
       "2           1        1      2  \n",
       "3           2        0      3  \n",
       "4           1        1      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(csv_path)\n",
    "test = pd.read_csv(csv_path2)\n",
    "\n",
    "full_data = [train, test]\n",
    "\n",
    "# Some extra features, not necessarily important\n",
    "# Gives the length of the name\n",
    "# train['Name_length'] = train['Name'].apply(len)\n",
    "# test['Name_length'] = test['Name'].apply(len)\n",
    "train['Words_Count'] = train['Name'].apply(lambda x: len(x.split()))\n",
    "test['Words_Count'] = test['Name'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Feature engineering steps taken from Sina\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n",
    "\n",
    "# Feature selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1612316145190,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "ZO72mPnmhBdy"
   },
   "outputs": [],
   "source": [
    "# 分割\n",
    "y = train['Survived'].ravel()\n",
    "train = train.drop(['Survived'], axis=1)\n",
    "X = train.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458879,
     "status": "ok",
     "timestamp": 1612316629784,
     "user": {
      "displayName": "K S",
      "photoUrl": "",
      "userId": "11621002665546969972"
     },
     "user_tz": -540
    },
    "id": "y9H2gI0Wh5vx",
    "outputId": "dc41be53-cd70-411b-d8de-0e2e4415e4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【グリッドサーチ】\n",
      "最良条件:\n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, eta=0.015, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.0149999997, max_delta_step=0, max_depth=7,\n",
      "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "訓練スコア:\n",
      " 0.8517964071856288\n",
      "テストスコア:\n",
      " 0.8340807174887892\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチ\n",
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "# グリッドサーチ用のパラメータを辞書型で設定\n",
    "param = {'eta':[0.01, 0.015, 0.025, 0.3],\n",
    "         'max_depth':[3, 5, 6, 7, 9, 12],\n",
    "         'min_child_weight':[1, 3, 5, 7],\n",
    "         'subsample':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "         'colsample_bytree':[0.6, 0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "score = gredSerch(gbm, param, 4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model     score            description\n",
      "0  RandomForestClassifier  0.739910               チューニングなし\n",
      "1  RandomForestClassifier  0.786517                グリッドサーチ\n",
      "2           XGBClassifier  0.674157               チューニングなし\n",
      "3           XGBClassifier  0.741573                グリッドサーチ\n",
      "4           XGBClassifier  0.834081  グリッドサーチ & 特徴量エンジニアリング\n"
     ]
    }
   ],
   "source": [
    "result_table = result_table.append({'model': 'XGBClassifier',\n",
    "                                    'score': score,\n",
    "                                    'description': 'グリッドサーチ & 特徴量エンジニアリング'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【グリッドサーチ】\n",
      "最良条件:\n",
      " RandomForestClassifier(max_depth=8, min_samples_leaf=5)\n",
      "訓練スコア:\n",
      " 0.8517964071856288\n",
      "テストスコア:\n",
      " 0.8295964125560538\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチ用のパラメータを辞書型で設定\n",
    "param = {'max_depth':[5, 8, 15, 25, 30, None],\n",
    "         'min_samples_leaf':[1, 2, 5, 10],\n",
    "         'min_samples_split':[1, 2, 5, 10, 15, 100]}\n",
    "\n",
    "score = gredSerch(RandomForestClassifier(), param, 4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model     score            description\n",
      "0  RandomForestClassifier  0.739910               チューニングなし\n",
      "1  RandomForestClassifier  0.786517                グリッドサーチ\n",
      "2           XGBClassifier  0.674157               チューニングなし\n",
      "3           XGBClassifier  0.741573                グリッドサーチ\n",
      "4           XGBClassifier  0.834081  グリッドサーチ & 特徴量エンジニアリング\n",
      "5  RandomForestClassifier  0.829596  グリッドサーチ & 特徴量エンジニアリング\n"
     ]
    }
   ],
   "source": [
    "result_table = result_table.append({'model': 'RandomForestClassifier',\n",
    "                                    'score': score,\n",
    "                                    'description': 'グリッドサーチ & 特徴量エンジニアリング'}, ignore_index=True)\n",
    "print(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboostの場合はグリッドサーチにてチューニングを行うと精度が上がった。\n",
    "しかし、ランダムフォレストの場合は精度が下がった（過学習が起きた）。\n",
    "\n",
    "特徴量エンジニアリングを行うと、両者ともに精度が大きく上がった。\n",
    "データの前処理をどのように行うかが、結果に大きく影響するということが分かった。\n",
    "\n",
    "一番精度の良かった４番のモデルで、kaggleへの提出を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :  0.834\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(colsample_bytree=0.7,\n",
    "                          eta=0.01,\n",
    "                          max_depth=6,\n",
    "                          min_child_weight=1,\n",
    "                          subsample=0.6)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# テストデータを使ったモデルの検証\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "# out[score depth3 leaf5:  1.000]\n",
    "print('score :  {:0.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_XG = model.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({'PassengerId':PassengerId, 'Survived': prediction_XG})\n",
    "out_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggleに提出した結果、スコアは\n",
    "「0.77990」だった。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNn+vJYY7xlbTVLoN6NweJC",
   "collapsed_sections": [],
   "name": "splint_2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
