{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*データセットの読み込み*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "csv_path = \"../../../input/house-prices-advanced-regression-techniques/train.csv\" # ファイル名（パス）を指定する\n",
    "data = pd.read_csv(csv_path)\n",
    "data = data.loc[:,['GrLivArea','YearBuilt','SalePrice']]\n",
    "\n",
    "# 欠損値を埋める\n",
    "data = data.fillna(df.median())\n",
    "\n",
    "# 抽出\n",
    "X = data.loc[:,['GrLivArea','YearBuilt']].values\n",
    "y = data.loc[:,['SalePrice']].values\n",
    "# 対数変換\n",
    "X = np.log(X)\n",
    "y = np.log(y)\n",
    "# 分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 99)\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果比較用のクラス\n",
    "class Show_result():\n",
    "    def __init__(self):\n",
    "        self.cols = [\"   RMSE train data\",\"RMSE test data\", \"モデル名\"]\n",
    "        self.result_df = pd.DataFrame(index=[], columns=self.cols)\n",
    "\n",
    "    def show_rsme(self, model_name, y_train, y_train_pred, y_test, y_pred):\n",
    "        \n",
    "        rsme1 = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        rsme2 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        record = pd.Series([rsme1, rsme2, model_name], index=self.result_df.columns)\n",
    "        \n",
    "        self.result_df = self.result_df.append(record, ignore_index=True)\n",
    "        \n",
    "        print(self.result_df.sort_values('RMSE test data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***【問題1】ブレンディングのスクラッチ実装***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchBlending():\n",
    "    \"\"\"\n",
    "    ブレンディングのスクラッチ実装\n",
    "    \"\"\"\n",
    "    def predict(self, X_test, model_list, weighted_average = None):\n",
    "        \n",
    "        # 予測値の変数（空）を宣言\n",
    "        y_pred_list = np.empty((X_test.shape[0], len(model_list)))\n",
    "        \n",
    "        # モデルの数だけループ\n",
    "        for i in range(len(model_list)):\n",
    "        \n",
    "            # それぞれのモデルより予測値を取得し、リストへ格納していく\n",
    "            y_pred_list[:,i] = model_list[i].predict(X_test)\n",
    "        \n",
    "        # 重み付けをしない場合\n",
    "        if weighted_average is None:\n",
    "            # 予測値の平均を算出\n",
    "            y_pred_list = np.average(y_pred_list, axis = 1)\n",
    "        # 重み付けをする場合\n",
    "        else:\n",
    "            # 未実装\n",
    "            pass\n",
    "        \n",
    "        return y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data モデル名\n",
      "0            0.196419         0.18574  決定木\n"
     ]
    }
   ],
   "source": [
    "# 決定木\n",
    "d_tree = tree.DecisionTreeRegressor(max_depth=5)\n",
    "d_tree = d_tree.fit(X_train, y_train)\n",
    "y_train_pred = d_tree.predict(X_train)\n",
    "y_pred = d_tree.predict(X_test)\n",
    "\n",
    "show_result = Show_result()\n",
    "show_result.show_rsme(\"決定木\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data  モデル名\n",
      "0            0.196419        0.185740   決定木\n",
      "1            0.219077        0.188343  線形回帰\n"
     ]
    }
   ],
   "source": [
    "# 線形回帰\n",
    "lr = LinearRegression()\n",
    "lr = lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "show_result.show_rsme(\"線形回帰\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data  モデル名\n",
      "0            0.196419        0.185740   決定木\n",
      "1            0.219077        0.188343  線形回帰\n",
      "2            0.215512        0.189379   SVM\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svr = svm.SVR()\n",
    "svr = svr.fit(X_train, y_train)\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "show_result.show_rsme(\"SVM\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data       モデル名\n",
      "3            0.084371        0.180743  ランダムフォレスト\n",
      "0            0.196419        0.185740        決定木\n",
      "1            0.219077        0.188343       線形回帰\n",
      "2            0.215512        0.189379        SVM\n"
     ]
    }
   ],
   "source": [
    "# ランダムフォレスト\n",
    "rfr = RandomForestRegressor()\n",
    "rfr = rfr.fit(X_train, y_train)\n",
    "y_train_pred = rfr.predict(X_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "show_result.show_rsme(\"ランダムフォレスト\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data                             モデル名\n",
      "4            0.168740        0.175593  ブレンディング（決定木、線形回帰、SVM、ランダムフォレスト）\n",
      "3            0.084371        0.180743                        ランダムフォレスト\n",
      "0            0.196419        0.185740                              決定木\n",
      "1            0.219077        0.188343                             線形回帰\n",
      "2            0.215512        0.189379                              SVM\n"
     ]
    }
   ],
   "source": [
    "# ブレンディング\n",
    "model_list = [d_tree, lr, svr, rfr] # 決定木、線形回帰、SVM、ランダムフォレスト\n",
    "scr_bl = ScratchBlending()\n",
    "y_train_pred = scr_bl.predict(X_train, model_list)\n",
    "y_pred = scr_bl.predict(X_test, model_list)\n",
    "\n",
    "show_result.show_rsme(\"ブレンディング（決定木、線形回帰、SVM、ランダムフォレスト）\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***【問題2】バギングのスクラッチ実装***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchBugging():\n",
    "    \"\"\"\n",
    "    バギングのスクラッチ実装\n",
    "    \n",
    "    model : モデル\n",
    "    n_estimators : 学習回数\n",
    "    train_samples : 学習時にトレインデータから抽出するデータの割合\n",
    "    \"\"\"\n",
    "    def __init__(self, model, n_estimators = 50, train_samples = 0.8):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.model = model\n",
    "        self.n_estimators = n_estimators\n",
    "        self.train_samples = train_samples\n",
    "        \n",
    "        self.model_list = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # 学習回数の数だけループ\n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            # データを分割\n",
    "            X_train, _, y_train, _ = train_test_split(X, y, train_size = self.train_samples)\n",
    "            # 学習\n",
    "            model = self.model.fit(X_train, y_train)\n",
    "            # 学習済モデルをリストへ追加\n",
    "            self.model_list.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # 予測値の変数（空）を宣言\n",
    "        y_pred_list = np.empty((X.shape[0], self.n_estimators))\n",
    "        \n",
    "        # モデルの数だけループ\n",
    "        for i, model in enumerate(self.model_list):\n",
    "            \n",
    "            # それぞれのモデルより予測値を取得し、リストへ格納していく\n",
    "            y_pred_list[:,i] = model.predict(X)\n",
    "        \n",
    "        # 予測値の平均を算出\n",
    "        y_pred_list = np.average(y_pred_list, axis = 1)\n",
    "        \n",
    "        return y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data                             モデル名\n",
      "4            0.168740        0.175593  ブレンディング（決定木、線形回帰、SVM、ランダムフォレスト）\n",
      "3            0.084371        0.180743                        ランダムフォレスト\n",
      "0            0.196419        0.185740                              決定木\n",
      "5            0.200446        0.185921                        バギング（決定木）\n",
      "1            0.219077        0.188343                             線形回帰\n",
      "2            0.215512        0.189379                              SVM\n"
     ]
    }
   ],
   "source": [
    "# バギング（決定木）\n",
    "d_tree = tree.DecisionTreeRegressor(max_depth=5)\n",
    "scr_bug = ScratchBugging(d_tree)\n",
    "scr_bug.fit(X_train, y_train)\n",
    "y_train_pred = d_tree.predict(X_train)\n",
    "y_pred = d_tree.predict(X_test)\n",
    "\n",
    "show_result.show_rsme(\"バギング（決定木）\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***【問題3】スタッキングのスクラッチ実装***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchStacking():\n",
    "    \"\"\"\n",
    "    スタッキングのスクラッチ実装\n",
    "    \n",
    "    base_models : ベースモデルのリスト\n",
    "    meta_model : メタモデル\n",
    "    n_splits : クロスバリデーション時の分割数\n",
    "    \"\"\"\n",
    "    def __init__(self, base_models, meta_model, n_splits=4):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    \"\"\"\n",
    "    fit\n",
    "    学習を行う\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # KFoldのインスタンス\n",
    "        kf = KFold(n_splits = self.n_splits, shuffle = True)\n",
    "        # oofの変数（空）\n",
    "        oof = np.zeros([X.shape[0], len(self.base_models)])\n",
    "        \n",
    "        # ベースモデルの数だけループ\n",
    "        for i, base_model in enumerate(self.base_models):\n",
    "            \n",
    "            # 学習済モデルの変数（空）\n",
    "            learned_models_list = []\n",
    "            \n",
    "            # クロスバリデーションを行うループ\n",
    "            for train_index, test_index in kf.split(X): \n",
    "\n",
    "                # ベースモデルで学習\n",
    "                base_model.fit(X[train_index], y[train_index])\n",
    "                # 学習済モデルをリストに追加\n",
    "                learned_models_list.append(base_model)\n",
    "                # 推定\n",
    "                y_pred = base_model.predict(X[test_index])\n",
    "                # 推定結果をoofに格納\n",
    "                oof[test_index, i] = y_pred.flatten()\n",
    "                \n",
    "            # 学習済ベースモデルのリストでベースモデルを上書き\n",
    "            self.base_models[i] = learned_models_list\n",
    "        \n",
    "        # oofを特徴量としてメタモデルで学習\n",
    "        self.meta_model.fit(oof, y)\n",
    "        \n",
    "    \"\"\"\n",
    "    predict\n",
    "    推定を行う\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        \n",
    "        new_features = np.zeros([X.shape[0], len(self.base_models)])\n",
    "        \n",
    "        # ベースモデルの数だけループ\n",
    "        for i, base_models in enumerate(self.base_models):\n",
    "            \n",
    "            # 予測値の変数（空）を宣言\n",
    "            y_pred_list = np.empty((X.shape[0], len(base_models)))\n",
    "            \n",
    "            # ベースモデルの数だけループ\n",
    "            for j, base_model in enumerate(base_models):\n",
    "            \n",
    "                # それぞれのモデルより予測値を取得し、リストへ格納していく\n",
    "                y_pred_list[:,j] = base_model.predict(X)\n",
    "            \n",
    "            # 予測値の平均を算出し、新しい特徴量とする\n",
    "            new_features[:,i] = np.average(y_pred_list, axis = 1)\n",
    "            \n",
    "        # 作成した特徴量でメタモデルにより推定\n",
    "        y_pred = self.meta_model.predict(new_features)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RMSE train data  RMSE test data                             モデル名\n",
      "4            0.168740        0.175593  ブレンディング（決定木、線形回帰、SVM、ランダムフォレスト）\n",
      "3            0.084371        0.180743                        ランダムフォレスト\n",
      "0            0.196419        0.185740                              決定木\n",
      "5            0.200446        0.185921                        バギング（決定木）\n",
      "1            0.219077        0.188343                             線形回帰\n",
      "2            0.215512        0.189379                              SVM\n",
      "6            0.185492        0.194540   スタッキング（決定木、線形回帰、SVR。ランダムフォレスト）\n"
     ]
    }
   ],
   "source": [
    "# スタッキング\n",
    "rfr = RandomForestRegressor()\n",
    "model_list = [d_tree, lr, svr] # 決定木、線形回帰、SVR\n",
    "scr_st = ScratchStacking(model_list, rfr) # ランダムフォレスト\n",
    "scr_st.fit(X_train, y_train)\n",
    "y_train_pred = scr_st.predict(X_train)\n",
    "y_pred = scr_st.predict(X_test)\n",
    "\n",
    "show_result.show_rsme(\"スタッキング（決定木、線形回帰、SVR。ランダムフォレスト）\", y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
